---
title: "Model - Yule Simon"
author: "Gabrielle Lemire"
date: "3/12/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Component Distribution for Simulated Genetic Networks

```{r, warning=FALSE}
library(ggplot2)
library(rlist)
library(reshape2)
library(rstanarm)
library(boot)

sim_dist_100 = read.csv("sim_dists.csv")
true_dist_1 = read.csv("true_dist.csv")
samp_prop = seq(from = .95, to = 0.2, by = -0.05)
# load extracted dataset
```

## Yule-Simon Model for True Dist

```{r, echo=FALSE}
library(VGAM)
# true_dist_1

# yulesimon(link = "loge", irho = NULL, nsimEIM = 200, zero = NULL)
# https://www.rdocumentation.org/packages/VGAM/versions/0.9-7/topics/yulesimon
# drop 0's got error with them
true_temp = true_dist_1[c(1,2,3,4,5,6,7,8,9, 11, 12, 14, 20, 23),]
# by hand - will need to do by loop
df_true = as.data.frame(matrix(nrow=sum(true_temp$x), ncol=1))
df_true[1:659,1]=1
df_true[(659+1):(659+102),1]=2
df_true[(761+1):(761+24),1]=3
df_true[(785+1):(785+15),1]=4
df_true[(800+1):(800+9),1]=5
df_true[(809+1):(809+4),1]=6
df_true[(813+1):(813+3),1]=7
df_true[(816+1):(816+3),1]=8
df_true[(819+1):(819+4),1]=9
df_true[(823+1):(823+1),1]=11
df_true[(824+1):(824+2),1]=12
df_true[(826+1):(826+1),1]=14
df_true[(827+1):(827+1),1]=20
df_true[(828+1):(828+1),1]=23

# for (row in 1:23){
#   df_true[] = true_temp[row]
# }

model <- vglm(x ~ X, yulesimon, data = true_temp, trace = TRUE)
# coef(model, matrix = TRUE)
summary(model)

# https://www.rdocumentation.org/packages/VGAM/versions/0.8-3/topics/predict.vglm
true_temp$predict = predict(model, newdata=true_temp$x, type="response") # lol results make no sense 
#maybe predicting on link scale


```

not sure if this is releva
-sizes of each cluster is y, intercept only... estimate yule-simon... not assuming it varies with covariate... or could pile together and have sampling rate as x value (but would need to understand model better because knowing that's useful)
-use predict to see (and find any diagnostic plots for vglm - see if there's patterns, etc - check package doc, software paper).. power law might not be accurate depending how end trails off
-vglm help file to help for that (or the package file)
-give understanding of yule-simon family next meeting (what is a vglm, etc) & how it relates to glm/what i've seen already


- what is this error that geom_smooth removed non-finite values
- model_lm = glm(abs(jitter(value))~X,family=Gamma(link="log"), data=df) <-- did not converge?
- model_true = glm(abs(jitter(x))~X,family=Gamma(link="log"), data=true_dist_1)
 <- also did not converge
 - Note there are lots of warnings but I hid them
 
 - log scale on y axis (prob most of change is in tails which is currently hard to see )
 - exponential (decay maybe overspursed) - do we see consistent across sampling rates (how parameters change)... if a glm isn't converging can increase the # of iterations that it runs (could need more time)
- include a random effect
- *Note: Each simulation within one proportion has its own random effect.*
- what is the model form we want (quasipoisson, vs glmer with random effect b/c correlated between sims), sledgehammer - if it were exponential what would the rate param be... try a few diff ones (can get form for mle - if this were gamma (for alpha beta what would it be) - if I plot over my data... 
-for component dist ppl often use power law distribution yule-simon dist (how to estimate params for this - or write optimizer) -- if none of the standard ones handle it well it's one of the few that follows this log-log (versus just the log in the others we're looking at)... how does shape change with log y only, how does shape change with log y and log x

- is there a poisson for size and number of times that size occurred - doesn't look like we can do for glm
- what we can do to expand (637 becomes 637 rows with 1, X1, 1)... ex: some function will do that (maybe "expand") (b/c we want each draw to be one cluster - what size is it)
- then fit with just intercept term... x is a function of 1 + (1|variable)... single poisson with extra variability from diff simulations ... 
- if this doesn't work can try the Yule-Simon (see if there's an implementation in R) 

- big question after will be how to move parameters in this situation into bigger epidemic model

- random websites:
- https://stats.stackexchange.com/questions/153611/interpreting-random-effect-%20variance-in-glmer
- https://en.wikipedia.org/wiki/Yule%E2%80%93Simon_distribution
